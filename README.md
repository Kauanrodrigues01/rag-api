# ğŸ“š Portfolio RAG API

**Portfolio RAG API** Ã© uma API moderna e assÃ­ncrona desenvolvida com **FastAPI**, projetada para integrar dados pessoais (como currÃ­culo, projetos e experiÃªncias) em um pipeline **RAG (Retrieval-Augmented Generation)** com LLMs, utilizando **LangChain**, **ChromaDB**, **OpenAI Embeddings** e **Jinja2** para gerenciamento via interface web.

Com esta API, desenvolvedores podem fazer upload de arquivos PDF contendo dados sobre si mesmos e permitir que usuÃ¡rios faÃ§am perguntas e obtenham respostas contextuais baseadas nesses dados.

---

## âœ¨ Funcionalidades

* âœ… Upload de documentos PDF com extraÃ§Ã£o e divisÃ£o em *chunks*
* ğŸ” Busca semÃ¢ntica via embeddings + ChromaDB
* ğŸ¤– IntegraÃ§Ã£o com LLM (OpenAI GPT-3.5) para respostas contextuais via LangChain
* ğŸ§  TÃ©cnica de overlap nos chunks para manter o contexto
* ğŸ—ƒï¸ Banco de dados relacional (PostgreSQL) com SQLAlchemy para gerenciar documentos
* ğŸš® DeleÃ§Ã£o automÃ¡tica dos chunks ao excluir um documento
* ğŸ”’ ProteÃ§Ã£o de rotas via API Key (`X-API-KEY`)
* ğŸŒ Interface web usando Jinja2 (HTML, CSS, JS) para gerenciar documentos
* âš¡ Uso de `BackgroundTasks` do FastAPI para paralelizar operaÃ§Ãµes no vector store e melhorar performance (+70%)

---

## ğŸ§  Como funciona o RAG

1. **Upload de PDF**: O arquivo Ã© carregado, processado, dividido em chunks e enviado para a vector store.
2. **Armazenamento**: Os chunks sÃ£o salvos com identificadores Ãºnicos no ChromaDB e os metadados no PostgreSQL.
3. **Pergunta do usuÃ¡rio**: A pergunta Ã© embutida como vetor e comparada com os chunks via LangChain.
4. **Respostas contextuais**: Os melhores chunks sÃ£o combinados e enviados ao LLM, que retorna uma resposta rica em markdown.

---

## ğŸ› ï¸ Tecnologias Utilizadas

As principais tecnologias utilizadas neste projeto incluem:

* **FastAPI**: Framework web assÃ­ncrono para construÃ§Ã£o da API.
* **LangChain**: OrquestraÃ§Ã£o do pipeline RAG com LLM.
* **OpenAI**: Embeddings e modelo GPT-3.5 para geraÃ§Ã£o de respostas.
* **ChromaDB**: Armazenamento vetorial para busca semÃ¢ntica.
* **SQLAlchemy Async + PostgreSQL**: Banco relacional para metadados dos documentos.
* **Jinja2**: RenderizaÃ§Ã£o de templates para a interface de administraÃ§Ã£o.
* **Docker**: Empacotamento e deploy dos serviÃ§os.
* **Pytest**: Testes automatizados e cobertura.

---

## ğŸš€ Executando Localmente com Docker

### ğŸ”§ PrÃ©-requisitos

* Docker + Docker Compose
* OpenAI API Key

### 1. Crie seu `.env`

```env
OPENAI_API_KEY=sk-...
VECTOR_STORE_PATH=./chroma_db
DATABASE_URL=postgresql+asyncpg://user:pass@db:5432/dbname
API_KEY_SECRET=minha-chave-secreta
```

### 2. Suba os containers

```bash
docker compose up --build
```

### ğŸŒ Acesse:

* API Docs: [http://localhost:8000/docs](http://localhost:8000/docs)
* Painel Admin: [http://localhost:8000/admin](http://localhost:8000/admin)
* PGAdmin: [http://localhost:5050](http://localhost:5050)

---

## ğŸ“¦ Endpoints Principais

| MÃ©todo | Endpoint            | Protegido por API Key? | DescriÃ§Ã£o                                                       |
| ------ | ------------------- | ---------------------- | --------------------------------------------------------------- |
| POST   | `/documents`        | âœ…                      | Faz upload de 1 ou mais PDFs e envia chunks para o vector store |
| GET    | `/documents`        | âœ…                      | Lista os documentos salvos no banco                             |
| DELETE | `/documents/{id}`   | âœ…                      | Deleta o documento e seus chunks na vector store                |
| POST   | `/rag/ask-question` | âŒ                      | Faz uma pergunta com base nos documentos processados            |

**Para rotas protegidas, envie o header:**

```
X-API-KEY: <sua-chave>
```

---


## ğŸ”’ SeguranÃ§a

* Todas as rotas de CRUD de documentos sÃ£o protegidas por API Key.
* `get_api_key()` verifica o header `X-API-KEY` com um segredo definido no `.env`.
* Rodando com usuÃ¡rio nÃ£o privilegiado no Docker.
* SeparaÃ§Ã£o clara entre lÃ³gica de LLM e manipulaÃ§Ã£o de arquivos.

---

## ğŸ“Š MÃ©tricas de Performance

* UtilizaÃ§Ã£o de `BackgroundTasks` reduziu o tempo de resposta do endpoint de upload de documentos em \~70%
* Arquitetura desacoplada com ChromaDB e LangChain
* Docker com multi-stage build e imagens otimizadas

---

## ğŸ’¡ MotivaÃ§Ã£o

Esse projeto nasceu da necessidade de fornecer respostas automÃ¡ticas, seguras e contextualizadas para perguntas sobre o desenvolvedor (portfÃ³lio pessoal), transformando arquivos estÃ¡ticos em dados consultÃ¡veis via IA generativa.

---

## ğŸ§ª Futuras Melhorias

* ğŸ” Suporte a autenticaÃ§Ã£o OAuth2/JWT
* ğŸ§  Acompanhamento de perguntas e estatÃ­sticas
* ğŸŒ Deploy com HTTPS e CI/CD
* ğŸ–¼ï¸ Suporte a outros tipos de arquivo alÃ©m de PDF
* ğŸ“¦ Plugin para integraÃ§Ã£o com portfÃ³lios pÃºblicos
